{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c46dfdd",
   "metadata": {},
   "source": [
    "You need to install PyWavelet if necessary: pip install pywavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f36bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4409a58",
   "metadata": {},
   "source": [
    "Visualization functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63167343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshowgray(im, vmin=None, vmax=None):\n",
    "    plt.imshow(im, cmap=plt.get_cmap('gray'), vmin=vmin, vmax=vmax)\n",
    "\n",
    "    \n",
    "def wavMask(dims, scale):\n",
    "    sx, sy = dims\n",
    "    res = np.ones(dims)\n",
    "    NM = np.round(np.log2(dims))\n",
    "    for n in range(int(np.min(NM)-scale+2)//2):\n",
    "        res[:int(np.round(2**(NM[0]-n))), :int(np.round(2**(NM[1]-n)))] = \\\n",
    "            res[:int(np.round(2**(NM[0]-n))), :int(np.round(2**(NM[1]-n)))]/2\n",
    "    return res\n",
    "\n",
    "\n",
    "def imshowWAV(Wim, scale=1):\n",
    "    plt.imshow(np.abs(Wim)*wavMask(Wim.shape, scale), cmap = plt.get_cmap('gray'))\n",
    "\n",
    "    \n",
    "def coeffs2img(LL, coeffs):\n",
    "    LH, HL, HH = coeffs\n",
    "    return np.vstack((np.hstack((LL, LH)), np.hstack((HL, HH))))\n",
    "\n",
    "\n",
    "def unstack_coeffs(Wim):\n",
    "        L1, L2  = np.hsplit(Wim, 2) \n",
    "        LL, HL = np.vsplit(L1, 2)\n",
    "        LH, HH = np.vsplit(L2, 2)\n",
    "        return LL, [LH, HL, HH]\n",
    "\n",
    "    \n",
    "def img2coeffs(Wim, levels=4):\n",
    "    LL, c = unstack_coeffs(Wim)\n",
    "    coeffs = [c]\n",
    "    for i in range(levels-1):\n",
    "        LL, c = unstack_coeffs(LL)\n",
    "        coeffs.insert(0,c)\n",
    "    coeffs.insert(0, LL)\n",
    "    return coeffs\n",
    "    \n",
    "    \n",
    "def dwt2(im):\n",
    "    coeffs = pywt.wavedec2(im, wavelet='db4', mode='per', level=4)\n",
    "    Wim, rest = coeffs[0], coeffs[1:]\n",
    "    for levels in rest:\n",
    "        Wim = coeffs2img(Wim, levels)\n",
    "    return Wim\n",
    "\n",
    "\n",
    "def idwt2(Wim):\n",
    "    coeffs = img2coeffs(Wim, levels=4)\n",
    "    return pywt.waverec2(coeffs, wavelet='db4', mode='per')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182ae8f",
   "metadata": {},
   "source": [
    "Before we dive into wavelet transforms, we need a nice image to perform the tests. The provided brain.npz file from the webpage has a very pretty brain image (note it is complex-valued!). Run the cell below to load this and other data, explained later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d167be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('brain.npz')\n",
    "im, mask_unif, mask_vardens, pdf_unif, pdf_vardens = \\\n",
    "data['im'], data['mask_unif'], data['mask_vardens'], data['pdf_unif'], data['pdf_vardens'], "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36435e",
   "metadata": {},
   "source": [
    "Here's an example of how to compute a Daubechies wavelet transform, display it, and reconstruct it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Wim = dwt2(im)\n",
    "im2 = idwt2(Wim)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "imshowgray(np.abs(im))\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "imshowWAV(Wim)\n",
    "plt.title('DWT')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "imshowgray(np.abs(im2))\n",
    "plt.title('Reconstruction')\n",
    "\n",
    "print('Reconstruction error:', np.linalg.norm(im - im2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a61d47c",
   "metadata": {},
   "source": [
    "### Wavelet thresholding\n",
    "\n",
    "Threshold the wavelet coefficients retaining only the largest 20% of the coefficients. Plot the masked wavelet coefficients. What has been thresholded?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5227d8df",
   "metadata": {},
   "source": [
    "### Sampled Fourier\n",
    "An important aspect of random frequency-domain sampling is matching the power spectrum of the image. Since the energy in many images is concentrated in lower spatial frequencies, more samples should be allocated there. We have provided two 3-fold undersampling masks for you. The random masks are in the variables mask_unif and mask_vardens and were drawn from probability density functions (PDF) given by the variables pdf_unif and pdf_vardens, respectively. Compute the 2D Fourier transform of the image using a centered 2D FFT. Display the mask and the pdfs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fadc2dd",
   "metadata": {},
   "source": [
    "Multiply by the uniform mask, divide by the appropriate PDF (called density compensation), and compute the zero-filled Fourier transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c21fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft2c(x):\n",
    "    return 1 / np.sqrt(np.prod(x.shape)) * np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(x)))\n",
    "\n",
    "def ifft2c(y):\n",
    "    return np.sqrt(np.prod(y.shape)) * np.fft.ifftshift(np.fft.ifft2(np.fft.fftshift(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5348fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = fft2c(im);\n",
    "Mu = (M * mask_vardens) / pdf_vardens;\n",
    "imu = ifft2c(Mu);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f0d0b",
   "metadata": {},
   "source": [
    "Display the image and the difference image compared to original image. Is the aliasing white random noise? Repeat for the variable density mask. What happened now? Both use a similar number of samples, but which gives you a better reconstruction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b4d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshowgray(np.abs(imu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4726c1e",
   "metadata": {},
   "source": [
    "### 2D POCS\n",
    "\n",
    "Extend your 1D POCS algorithm for 2D images. Add another step of computing the wavelet transform before the soft-thresholding and the inverse wavelet transform after the soft-thresholding. Make sure that your SoftThresh function works for complex-valued data, as was mentioned earlier.\n",
    "\n",
    "Reconstruct the images from both the uniform and the variable density under-sampled data. First get an idea of reasonable values for λ\n",
    "\n",
    "by examining what would be thresholded. You can do this using\n",
    "\n",
    "Wimu = dwt2(imu)\n",
    "imshowgray(abs(Wimu) > lambda)\n",
    "\n",
    "Don't use imshowWAV for this, since it will scale the different wavelet levels differently. You want a significant number of coefficients to be below λ\n",
    "\n",
    ", but not so many that too much detail will be lost!\n",
    "\n",
    "Start with the variable density data, and experiment with several values of λ\n",
    ". You should only need about 20 iterations, but start with fewer while you convince yourself it is working! Compare the result after soft-thresholding to a zero-filled density compensated reconstruction, the original image, and a the original image soft-thresholded. As an initial image to the POCS, use a zero-filled density compensated reconstruction, as it will converge faster. Show the image, and the difference image for the λ\n",
    "\n",
    "you find the most effective.\n",
    "\n",
    "Then try the uniform density data. Run for at least 50-100 iterations, since this converges slowly. If you want to speed up the convergence, start with a relatively large λ\n",
    "so that the recon will converge rapidly. Then, decrease λ using the previous recon as an initial image. For example, you might divide λ by two every 10 or 20 iterations (this is called continuation). Show the image, and the difference image for the λ (or the final λ if you use a sequence) that you find the most effective. Don’t spend too much time on this, the point should be clear by now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
